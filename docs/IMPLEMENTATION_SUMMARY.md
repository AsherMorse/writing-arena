# Implementation Plan Summary

**Quick Reference for Addressing Learning Science Concerns**

---

## ğŸ¯ Three Main Changes

### 1. Increase Phase Durations â±ï¸
- **Phase 1:** 2 min â†’ **4 min**
- **Phase 2:** 1.5 min â†’ **3 min**
- **Phase 3:** 1.5 min â†’ **3 min**
- **Total:** 5 min â†’ **10 min**

### 2. Reduce Peer Review Questions ğŸ“
- **From:** 5 questions (clarity, strengths, improvements, organization, engagement)
- **To:** 3 questions (main idea, one strength, one suggestion)

### 3. Implement Rank-Based Difficulty ğŸ–ï¸
- **Bronze:** 3 min writing (sentence-level)
- **Silver:** 4 min writing (paragraphs)
- **Gold:** 5 min writing (micro-essays)
- **Platinum+:** 6 min writing (AP-level FRQ)

---

## ğŸ“‹ Implementation Phases

### Phase 1: Critical Changes (Week 1-2)
**Priority:** ğŸ”´ Critical  
**Focus:** Timing and peer review questions

**Key Tasks:**
1. Update `lib/constants/scoring.ts` - Change durations to 240/180/180
2. Update `functions/session-orchestrator.ts` - Change hardcoded 90s to 180s
3. Update `components/ranked/PeerFeedbackContent.tsx` - Change 5 questions to 3
4. Update all API endpoints - Handle new 3-question format
5. Update validation logic - Check 3 fields instead of 5
6. Implement backward compatibility - Support old format during transition

**Files Changed:** ~10 files  
**Estimated Time:** 1-2 weeks

---

### Phase 2: Rank-Based Scaling (Week 3-4)
**Priority:** ğŸŸ¡ Medium  
**Focus:** Dynamic timing based on student rank

**Key Tasks:**
1. Create `lib/constants/rank-timing.ts` - Rank-based timing configuration
2. Update session creation - Pass rank and use rank-based durations
3. Update session orchestrator - Use rank for phase transitions
4. Create prompt complexity system - Rank-based guidance (optional)

**Files Changed:** ~5 files  
**Estimated Time:** 1-2 weeks

---

### Phase 3: Testing & Validation (Week 4)
**Priority:** ğŸŸ¡ Medium  
**Focus:** Ensure quality and reliability

**Key Tasks:**
1. Unit tests - Rank timing, migration, validation
2. Integration tests - Full session flow, API endpoints
3. User acceptance testing - Real scenarios, edge cases

**Files Changed:** ~5 test files  
**Estimated Time:** 1 week

---

## ğŸš€ Quick Start Guide

### Step 1: Update Constants (30 min)
```typescript
// lib/constants/scoring.ts
PHASE1_DURATION: 240,  // Was 120
PHASE2_DURATION: 180,  // Was 90
PHASE3_DURATION: 180,  // Was 90
```

### Step 2: Update Peer Feedback (2-3 hours)
```typescript
// components/ranked/PeerFeedbackContent.tsx
const [responses, setResponses] = useState({
  mainIdea: '',      // Was clarity
  strength: '',      // Was strengths
  suggestion: ''     // Was improvements (removed organization, engagement)
});
```

### Step 3: Update APIs (2-3 hours)
- Update `/api/evaluate-peer-feedback`
- Update `/api/batch-rank-feedback`
- Update `/api/generate-ai-feedback`
- Update prompt functions

### Step 4: Test Everything (1-2 days)
- Run existing tests
- Test full session flow
- Verify backward compatibility

---

## ğŸ“Š Impact Assessment

### Before Changes:
- âš ï¸ 5-minute cycle = cognitive overload
- âš ï¸ 5 questions in 90 seconds = shallow feedback
- âš ï¸ 90-second revision = cosmetic edits only
- âš ï¸ No rank-based scaffolding

### After Changes:
- âœ… 10-minute cycle = adequate time for learning
- âœ… 3 questions in 3 minutes = quality feedback possible
- âœ… 3-minute revision = meaningful changes possible
- âœ… Rank-based timing = proper scaffolding

---

## âš ï¸ Critical Considerations

### Backward Compatibility
- **Issue:** Existing sessions may have old 5-question format
- **Solution:** Migration utility converts old â†’ new format
- **Timeline:** Support both formats for 2-4 weeks, then deprecate

### Rank-Based Timing
- **Issue:** How to handle mixed-rank groups?
- **Solution:** Use median/average rank of group
- **Fallback:** Default to Silver tier timing if rank unavailable

### Testing Strategy
- **Unit Tests:** All new utilities and functions
- **Integration Tests:** Full session flow with new timings
- **E2E Tests:** User scenarios with different ranks
- **Backward Compatibility:** Test with old format data

---

## ğŸ“ˆ Success Metrics

### Immediate (Week 1-2):
- [ ] All phases use new durations
- [ ] Peer review uses 3 questions
- [ ] No breaking changes
- [ ] All tests pass

### Short-term (Week 3-4):
- [ ] Rank-based timing works
- [ ] No performance issues
- [ ] User feedback positive

### Long-term (Month 2+):
- [ ] Improved feedback quality metrics
- [ ] Better revision quality scores
- [ ] Increased student engagement
- [ ] Alignment with TWR principles validated

---

## ğŸ”— Related Documents

- **Full Implementation Plan:** `docs/IMPLEMENTATION_PLAN.md`
- **Feedback Analysis:** `docs/REVIEW_FEEDBACK_ANALYSIS.md`
- **Three Phase System:** `docs/7_Features/THREE_PHASE_BATTLE_SYSTEM.md`

---

## ğŸ’¡ Key Decisions Needed

1. **Backward Compatibility Timeline:** How long to support old format?
2. **Rank Calculation:** Average vs. median vs. leader's rank?
3. **Feature Rollout:** All at once or gradual with feature flags?
4. **Prompt Complexity:** Full filtering or just guidance?

---

## ğŸ“ Next Steps

1. âœ… Review implementation plan
2. â³ Get team approval
3. â³ Create GitHub issues
4. â³ Assign tasks
5. â³ Begin Phase 1 implementation

---

**Last Updated:** December 2024  
**Status:** Ready for Implementation


