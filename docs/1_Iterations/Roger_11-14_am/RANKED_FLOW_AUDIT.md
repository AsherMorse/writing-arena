# Ranked Flow: Mock vs Real - Complete Audit

## üîç Overview
This document audits the **entire ranked match flow** from start to finish, identifying what's real vs mock/placeholder.

---

## 1Ô∏è‚É£ Landing Page (`/ranked/page.tsx`)

### ‚úÖ REAL
- User profile data (rank, LP, display name)
- Trait selection UI (only "All Traits" enabled)
- Navigation to matchmaking

### ‚ö†Ô∏è MOCK / PLACEHOLDER
- **Trait-specific modes** - Only "All Traits" works, others say "Coming Soon"
  - Content, Organization, Grammar, Vocabulary, Mechanics modes disabled

---

## 2Ô∏è‚É£ Matchmaking (`/ranked/matchmaking/page.tsx`)

### ‚úÖ REAL
- Real Firestore queue join/leave
- Real-time listening for other players in queue
- Actual prompt selection from library (20 prompts)
- matchId generation
- TWR concepts carousel

### ‚ö†Ô∏è MOCK / PLACEHOLDER
- **AI Player Backfill** - Every 5 seconds, adds generated AI players
  - Line 82-97: `generateAIPlayer()` creates fake players with random ranks
  - AI players have hardcoded names: ProWriter99, WordMaster, EliteScribe, PenChampion
  - AI players have hardcoded avatars: üéØ, üìñ, ‚ú®, üèÖ
  - **Issue**: There's NO actual matchmaking algorithm checking for real players in other queues
  - **Result**: You always play with 4 AI bots, never real humans

### üìù Notes
- The queue system EXISTS and WORKS (Firestore integration is real)
- Real players DO appear in the queue
- Problem: No logic to wait for real players or create parties of real humans
- AI backfill happens too quickly (5 seconds) before real humans can match

---

## 3Ô∏è‚É£ Phase 1: Writing Session (`/ranked/session/page.tsx`)

### ‚úÖ REAL
- Real timer (4 minutes)
- Real word count
- Real AI evaluation via `/api/analyze-writing` (Claude API)
- Real feedback stored in Firestore
- Match state synchronization
- Real "Waiting for Players" screen
- TWR tips modal

### ‚ö†Ô∏è MOCK / PLACEHOLDER
- **AI Opponent Scores** - Session page doesn't generate AI scores, but passes through empty/mock aiScores array

---

## 4Ô∏è‚É£ Phase Rankings (After Phase 1) (`/ranked/phase-rankings/page.tsx`)

### ‚úÖ REAL
- Your actual score from AI evaluation
- Real countdown timer (10s)
- TWR concepts carousel
- Compact layout

### ‚ö†Ô∏è MOCK / PLACEHOLDER
- **AI Player Scores** - Lines 85-116
  ```typescript
  { 
    name: 'ProWriter99', 
    score: Math.round(65 + Math.random() * 25),  // RANDOM!
  },
  { 
    name: 'WordMaster', 
    score: Math.round(60 + Math.random() * 30),  // RANDOM!
  },
  // etc...
  ```
  - **Issue**: These are randomly generated scores, not from actual AI evaluation
  - **Issue**: Rankings shuffle each time page renders (now fixed with useMemo, but scores still random)

---

## 5Ô∏è‚É£ Phase 2: Peer Feedback (`/ranked/peer-feedback/page.tsx`)

### ‚úÖ REAL
- Real timer (3 minutes)
- Real AI evaluation via `/api/evaluate-peer-feedback` (Claude API)
- Real feedback stored in Firestore
- TWR tips modal
- Match state synchronization

### ‚ö†Ô∏è MOCK / PLACEHOLDER
- **Peer's Writing** - Lines 10-33: `MOCK_PEER_WRITINGS`
  - Hardcoded sample essays (2 options)
  - Line 49: `const [currentPeer] = useState(MOCK_PEER_WRITINGS[0])`
  - **Issue**: You're ALWAYS evaluating the same fake essay, not another player's actual writing
  - No retrieval of real peer writing from Firestore
  - Comment on line 49: `// In reality, match them with actual peer`

---

## 6Ô∏è‚É£ Phase Rankings (After Phase 2) (`/ranked/phase-rankings/page.tsx`)

### ‚úÖ REAL
- Your actual feedback evaluation score from AI

### ‚ö†Ô∏è MOCK / PLACEHOLDER
- **AI Player Scores** - Same random generation as Phase 1 rankings
- See section 4 above - same issue repeats

---

## 7Ô∏è‚É£ Phase 3: Revision (`/ranked/revision/page.tsx`)

### ‚úÖ REAL
- Real timer (4 minutes)
- Real AI feedback generation via `/api/generate-feedback` (Claude API)
- Real AI revision evaluation via `/api/evaluate-revision` (Claude API)
- Real feedback stored in Firestore
- TWR tips modal
- No sticky elements (scrolls smoothly)

### ‚ö†Ô∏è MOCK / PLACEHOLDER
- **Peer Feedback Display** - Lines 311-318: Comment says `{/* Peer Feedback - MOCK */}`
  - Hardcoded peer feedback text:
    ```
    "Your story has a great sense of mystery..."
    "Try adding more description about what Sarah is feeling..."
    ```
  - **Issue**: Not showing the actual feedback responses from Phase 2
  - Should retrieve from Firestore or URL params

---

## 8Ô∏è‚É£ Final Results (`/ranked/results/page.tsx`)

### ‚úÖ REAL
- Your actual scores from all 3 phases
- Composite score calculation (weighted)
- LP/XP/Points calculations
- **NOW SAVES TO FIRESTORE** (just fixed!)
- Retrieves real AI feedback from Firestore
- Shows "‚úì Real AI" badge when real feedback available
- Session history saved

### ‚ö†Ô∏è MOCK / PLACEHOLDER
- **AI Player Scores Across All 3 Phases** - Lines 133-170
  ```typescript
  const aiPlayers = [
    {
      name: 'ProWriter99',
      phase1: Math.round(65 + Math.random() * 25),  // RANDOM!
      phase2: Math.round(70 + Math.random() * 20),  // RANDOM!
      phase3: Math.round(75 + Math.random() * 15),  // RANDOM!
    },
    // ... 3 more AI players with random scores
  ];
  ```
  - **Issue**: AI opponents get randomly generated scores for all phases
  - They don't actually "compete" - their scores are fake
  - Rankings are based on these random scores vs your real scores

- **MOCK_PHASE_FEEDBACK Fallback** - Lines 11-62
  - Hardcoded generic feedback as fallback
  - Only shown if real AI feedback not available
  - Now properly attempts to load real feedback first

---

## üéØ SUMMARY OF MOCK/PLACEHOLDER ITEMS

### Critical Issues (Breaks Multiplayer Experience)

1. **No Real Player Matching** ‚úã CRITICAL
   - Location: `/ranked/matchmaking/page.tsx` lines 82-97
   - Issue: Always backfills with AI within 5 seconds
   - Impact: Players NEVER play against other humans, only bots

2. **Mock Peer Writing in Phase 2** ‚úã CRITICAL  
   - Location: `/ranked/peer-feedback/page.tsx` lines 10-33, 49
   - Issue: Always evaluating same 2 hardcoded essays
   - Impact: Not a real peer evaluation - you're not reading another player's work

3. **Random AI Opponent Scores** ‚ö†Ô∏è HIGH
   - Location: Multiple files (phase-rankings, results)
   - Issue: AI players get random scores, not from actual evaluation
   - Impact: Rankings are partly fake - only your score is real

4. **Mock Peer Feedback Display in Revision** ‚ö†Ô∏è MEDIUM
   - Location: `/ranked/revision/page.tsx` lines 311-318
   - Issue: Shows hardcoded peer feedback, not actual responses
   - Impact: Students don't see what their peer actually wrote about their work

### Minor/Acceptable Placeholders

5. **AI Player Names/Avatars** ‚ÑπÔ∏è LOW
   - Location: `/lib/matchmaking-queue.ts` lines 112-147
   - Issue: AI players have hardcoded names and avatars
   - Impact: Recognizable as bots, but acceptable for testing

6. **Trait-Specific Modes Disabled** ‚ÑπÔ∏è LOW
   - Location: `/ranked/page.tsx` line 146
   - Issue: Only "All Traits" mode works
   - Impact: Less variety, but clearly marked "Coming Soon"

---

## üîÑ Real vs Mock Data Flow Diagram

```
USER'S DATA:
‚úÖ Profile (real Firestore)
‚úÖ Writing (real)
‚úÖ Phase 1 Score (real Claude AI)
‚úÖ Phase 2 Score (real Claude AI)  
‚úÖ Phase 3 Score (real Claude AI)
‚úÖ AI Feedback (real, stored in Firestore)
‚úÖ LP/XP Changes (real, saved to Firestore)

AI OPPONENTS' DATA:
‚ùå Players (generated bots, not real humans)
‚ùå Phase 1 Scores (random 60-90)
‚ùå Phase 2 Scores (random 60-90)
‚ùå Phase 3 Scores (random 60-90)
‚ùå Writing content (never written by AI)
‚ùå Feedback (never given by AI)

PEER INTERACTION:
‚ùå Peer's writing you evaluate (hardcoded samples)
‚ùå Peer feedback shown to you (hardcoded text)
‚úÖ Your feedback evaluation (real AI judges quality)
```

---

## üí° RECOMMENDATIONS

### Priority 1: Enable Real Player Matching
**Problem**: Always plays with AI bots  
**Solution**: 
- Increase AI backfill delay from 5s to 30-60s
- Implement actual matchmaking that waits for real players
- Add "Play vs AI" option separate from "Ranked"
- Show party composition (X real players, Y AI) before match starts

### Priority 2: Implement Real Peer Writing Exchange
**Problem**: Not evaluating real peer work  
**Solution**:
- Store player writings in matchState
- In Phase 2, retrieve a real opponent's Phase 1 writing
- Round-robin assignment (Player 1 reviews Player 2, Player 2 reviews Player 3, etc.)

### Priority 3: Generate Real AI Opponent Scores
**Problem**: AI scores are random, not evaluated  
**Solution Option A (Quick):
- Generate AI writing using Claude
- Run it through same evaluation pipeline
- Store real scores

**Solution Option B (Better):
- Pre-generate 100+ AI-written essays at various skill levels
- Store in database with pre-calculated scores
- Assign appropriate AI essays based on player's rank

### Priority 4: Show Real Peer Feedback in Revision
**Problem**: Not showing actual peer comments  
**Solution**:
- Retrieve peer's Phase 2 responses from Firestore
- Display actual feedback instead of mock text
- Show peer's name/avatar for accountability

---

## üìä Current State Summary

| Component | Status | Notes |
|-----------|--------|-------|
| User Authentication | ‚úÖ Real | Firebase Auth |
| User Profile | ‚úÖ Real | Firestore |
| Matchmaking Queue | ‚úÖ Real | Firestore, but doesn't wait |
| AI Backfill | ‚ö†Ô∏è Too Fast | 5s delay, should be 30-60s |
| Player Names | ‚ùå Mock | AI-generated bots |
| Prompt Library | ‚úÖ Real | 20 real prompts |
| Phase 1 Writing | ‚úÖ Real | User's actual writing |
| Phase 1 Evaluation | ‚úÖ Real | Claude AI |
| Phase 1 Feedback Storage | ‚úÖ Real | Firestore |
| Phase 1 AI Scores | ‚ùå Mock | Random 60-90 |
| Phase 2 Peer Writing | ‚ùå Mock | Hardcoded samples |
| Phase 2 Evaluation | ‚úÖ Real | Claude AI |
| Phase 2 Feedback Storage | ‚úÖ Real | Firestore |
| Phase 2 AI Scores | ‚ùå Mock | Random 60-90 |
| Phase 3 AI Feedback Gen | ‚úÖ Real | Claude AI |
| Phase 3 Revision Eval | ‚úÖ Real | Claude AI |
| Phase 3 Feedback Storage | ‚úÖ Real | Firestore |
| Phase 3 Peer Feedback Display | ‚ùå Mock | Hardcoded text |
| Phase 3 AI Scores | ‚ùå Mock | Random 60-90 |
| Results Display | ‚úÖ Real | Your scores accurate |
| Results AI Feedback | ‚úÖ Real | Retrieves from Firestore |
| LP/XP/Points Save | ‚úÖ Real | Just fixed! |
| Session History | ‚úÖ Real | Saved to Firestore |
| Waiting Screens | ‚úÖ Real | Match sync works |
| TWR Carousels | ‚úÖ Real | Educational content |

---

## üéØ Bottom Line

**What Works Great:**
- Your entire evaluation pipeline (real Claude AI at every phase)
- Your feedback storage and retrieval
- Your profile updates (LP, XP, stats)
- Match synchronization between phases
- UI/UX and educational content

**What Needs Work:**
- üö® **Multiplayer is mostly simulated** - you're not playing against real humans
- üö® **Peer feedback loop is broken** - not exchanging real work
- üö® **AI opponents are hollow** - random scores, no actual content
- ‚úÖ But the INFRASTRUCTURE is there! Just needs the connections made.

The good news: The foundation is solid. All the Firestore structures, API endpoints, and UI components are in place. It's a matter of connecting the dots to enable real multiplayer interaction.

