# Writing Arena - AI-Powered Competitive Writing Platform

> Transform K-12 writing skills through competitive matches and AI-powered feedback

## ğŸ® Current Version: V1.0 - Core Platform âœ…

A fully functional competitive writing platform with three game modes, AI feedback, and character progression. Students compete in 4-minute writing battles, earn XP and ranks, and receive instant formative feedback from Claude AI.

---

## ğŸš€ Quick Start

### Installation
```bash
npm install
```

### Run Development Server
```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to see the app.

### Optional: Configure Claude AI
See `docs/5_Setup/SETUP_API.md` for instructions on enabling real AI feedback.
The app works with mock feedback if no API key is configured!

---

## âœ¨ V1 Features (Completed)

### ğŸ¯ Three Game Modes
1. **Practice Mode** - Solo training with AI feedback
2. **Quick Match** - Casual 6-player competitive matches
3. **Ranked Match** - Competitive play with LP and rank progression

### ğŸ¤– AI-Powered Feedback
- Claude Sonnet 4 integration
- Trait-by-trait scoring (Content, Organization, Grammar, Vocabulary, Mechanics)
- Specific strengths and improvement suggestions
- Next steps recommendations
- Mock fallback for testing without API key

### ğŸ¨ Complete User Experience
- Beautiful landing page with hero section
- Dashboard with stats and character display
- Mode selection modal
- Progressive setup wizards
- Live timers and word counters
- Matchmaking with party formation
- Real-time AI opponent simulation
- Competitive rankings and medals
- Victory celebrations and rewards

### ğŸŒ³ Character Progression
- 6 mastery levels: Seedling â†’ Sapling â†’ Young Oak â†’ Mature Oak â†’ Ancient Oak â†’ Legendary Redwood
- XP and points system
- Trait-specific leveling
- Visual progress tracking

### ğŸ† Competitive Systems
- Rankings and medals (ğŸ¥‡ğŸ¥ˆğŸ¥‰)
- League Points (LP) system for ranked play
- Victory bonuses
- Placement rewards
- Rank tiers (Bronze â†’ Silver â†’ Gold â†’ Platinum â†’ Diamond â†’ Master â†’ Grandmaster)

### ğŸ›¡ï¸ Quality Features
- Paste prevention (ensures original work)
- Responsive design (mobile, tablet, desktop)
- Smooth animations and transitions
- Loading states and error handling
- Professional UI with glassmorphism

---

## ğŸ“ Project Structure

```
writing-app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx                      # Landing page
â”‚   â”œâ”€â”€ dashboard/                    # Main dashboard
â”‚   â”œâ”€â”€ practice/                     # Solo training mode
â”‚   â”œâ”€â”€ quick-match/                  # Casual competitive
â”‚   â”œâ”€â”€ ranked/                       # Ranked competitive
â”‚   â”‚   â”œâ”€â”€ matchmaking/              # Matchmaking UI
â”‚   â”‚   â”œâ”€â”€ session/                 # Phase 1: Writing
â”‚   â”‚   â”œâ”€â”€ peer-feedback/           # Phase 2: Peer Feedback
â”‚   â”‚   â”œâ”€â”€ revision/                # Phase 3: Revision
â”‚   â”‚   â”œâ”€â”€ phase-rankings/          # Phase rankings display
â”‚   â”‚   â””â”€â”€ results/                 # Final results
â”‚   â””â”€â”€ api/                         # API routes
â”‚       â”œâ”€â”€ batch-rank-writings/     # Phase 1 batch ranking
â”‚       â”œâ”€â”€ batch-rank-feedback/     # Phase 2 batch ranking
â”‚       â”œâ”€â”€ batch-rank-revisions/    # Phase 3 batch ranking
â”‚       â””â”€â”€ generate-ai-*/           # AI content generation
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ranked/                      # Ranked mode components
â”‚   â”œâ”€â”€ shared/                      # Shared UI components
â”‚   â””â”€â”€ ui/                          # Base UI components
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â””â”€â”€ grading-prompts.ts      # â­ Centralized grading prompts
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ time-utils.ts           # â­ Time formatting utilities
â”‚   â”‚   â”œâ”€â”€ api-helpers.ts          # â­ API helper functions
â”‚   â”‚   â””â”€â”€ claude-parser.ts        # â­ Claude response parsing
â”‚   â”œâ”€â”€ constants/
â”‚   â”‚   â””â”€â”€ scoring.ts              # â­ Scoring constants
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useSession.ts           # Session management hook
â”‚   â””â”€â”€ services/                   # Firestore services
â”œâ”€â”€ FEATURE_CATALOG.md              # V1 vs PRD comparison
â”œâ”€â”€ V1_SUMMARY.md                   # Implementation achievements
â”œâ”€â”€ V2_ROADMAP.md                   # Future development plan
â”œâ”€â”€ SETUP_API.md                    # Claude API configuration
â””â”€â”€ PRD*.md                         # Product requirements
```

**â­ = Recently refactored for maintainability**

---

## ğŸ”§ Recent Refactoring (2024)

### Code Organization Improvements

We've recently refactored the codebase to improve maintainability and consistency:

#### 1. **Centralized Grading Prompts** (`lib/prompts/grading-prompts.ts`)
- All AI evaluation prompts in one place
- Easy to edit and maintain
- Consistent evaluation across all phases
- See [Editing Prompts](#-editing-prompts) section below

#### 2. **Utility Functions** (`lib/utils/`)
- **`time-utils.ts`**: Time formatting and color utilities
- **`api-helpers.ts`**: API key management and Claude API calls
- **`claude-parser.ts`**: Standardized JSON parsing from Claude responses

#### 3. **Scoring Constants** (`lib/constants/scoring.ts`)
- All magic numbers centralized (phase durations, score ranges, thresholds)
- Single source of truth for scoring configuration
- Easy to adjust scoring parameters

#### 4. **Improved Error Handling**
- Consistent API error handling across all routes
- Better logging and debugging
- Graceful fallbacks to mock data

**Impact**: ~500+ lines of duplicate code removed, better maintainability, easier to extend

---

## ğŸ‘¨â€ğŸ’» Developer Guide

### ğŸ“ Editing Prompts

All AI grading prompts are centralized in **`lib/prompts/grading-prompts.ts`**. This is the **single source of truth** for how AI evaluates student work.

#### File Structure

```typescript
lib/prompts/grading-prompts.ts
â”œâ”€â”€ getPhase1WritingPrompt()      // Phase 1: Writing evaluation
â”œâ”€â”€ getPhase2PeerFeedbackPrompt() // Phase 2: Peer feedback evaluation
â””â”€â”€ getPhase3RevisionPrompt()     // Phase 3: Revision evaluation
```

#### How to Edit a Prompt

1. **Open** `lib/prompts/grading-prompts.ts`
2. **Find** the prompt function you want to edit (e.g., `getPhase1WritingPrompt`)
3. **Edit** the prompt string directly
4. **Save** - Changes apply automatically to all API routes

#### Example: Adjusting Phase 1 Evaluation Criteria

```typescript
// In lib/prompts/grading-prompts.ts

export function getPhase1WritingPrompt(...) {
  return `You are a writing instructor...
  
  // Edit these criteria:
  SCORING CRITERIA:
  
  **Rank 1 (90-100)**: Mastery of 5+ TWR strategies...
  **Rank 2-3 (80-89)**: Strong use of 3-4 TWR strategies...
  // ... modify as needed
  `;
}
```

#### What Each Prompt Evaluates

- **Phase 1 (Writing)**: Initial writing quality, TWR strategies, content development
- **Phase 2 (Peer Feedback)**: Specificity, constructiveness, completeness, TWR references
- **Phase 3 (Revision)**: Application of feedback, meaningful improvements, TWR strategies

#### Testing Prompt Changes

1. Make your changes to `grading-prompts.ts`
2. Restart dev server: `npm run dev`
3. Run a test match in ranked mode
4. Check server logs for AI responses
5. Verify scores reflect your changes

---

### ğŸ”„ Understanding the Flow

#### Ranked Mode: Three-Phase Battle System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MATCHMAKING                            â”‚
â”‚  - Join queue or play against AI        â”‚
â”‚  - Fast-track button fills with AI      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: WRITING (5 min)              â”‚
â”‚  - Write response to prompt             â”‚
â”‚  - AI generates 4 opponent writings     â”‚
â”‚  - Batch ranking: All 5 evaluated       â”‚
â”‚  - Weight: 40%                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: PEER FEEDBACK (3 min)        â”‚
â”‚  - Review assigned peer's writing       â”‚
â”‚  - Answer 3 feedback questions          â”‚
â”‚  - AI generates 4 opponent feedbacks    â”‚
â”‚  - Batch ranking: All 5 evaluated       â”‚
â”‚  - Weight: 30%                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: REVISION (4 min)             â”‚
â”‚  - View original writing                â”‚
â”‚  - See AI & peer feedback               â”‚
â”‚  - Revise and improve                   â”‚
â”‚  - AI generates 4 opponent revisions    â”‚
â”‚  - Batch ranking: All 5 evaluated       â”‚
â”‚  - Weight: 30%                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESULTS                                â”‚
â”‚  - Composite score (weighted average)    â”‚
â”‚  - Rankings (1-5)                       â”‚
â”‚  - LP changes                           â”‚
â”‚  - XP rewards                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Key Components

**Session Management** (`lib/hooks/useSession.ts`)
- Centralized session state management
- Real-time Firestore synchronization
- Phase transitions and coordination
- Time remaining calculations

**Match Sync** (`lib/services/match-sync.ts`)
- Firestore operations for match state
- Peer assignment logic
- Feedback retrieval
- Rankings storage

**Batch Ranking APIs** (`app/api/batch-rank-*/`)
- Phase 1: `batch-rank-writings/route.ts`
- Phase 2: `batch-rank-feedback/route.ts`
- Phase 3: `batch-rank-revisions/route.ts`

All three routes:
1. Receive submissions from all players
2. Call centralized prompt functions
3. Send to Claude API for batch evaluation
4. Parse and return ranked results

#### Data Flow

```
Component (e.g., WritingSessionContent.tsx)
    â†“ submits writing
API Route (batch-rank-writings/route.ts)
    â†“ calls getPhase1WritingPrompt()
Centralized Prompt (grading-prompts.ts)
    â†“ returns prompt string
API Route
    â†“ sends to Claude API
Claude API
    â†“ returns JSON rankings
API Route
    â†“ parses with claude-parser.ts
Component
    â†“ displays results
```

---

### ğŸ†• Adding New Features

#### 1. Adding a New Phase

**Step 1: Create Component**
```typescript
// components/ranked/NewPhaseContent.tsx
export default function NewPhaseContent() {
  const { session, timeRemaining, submitPhase } = useSession();
  // ... component logic
}
```

**Step 2: Create API Route**
```typescript
// app/api/batch-rank-new-phase/route.ts
import { getNewPhasePrompt } from '@/lib/prompts/grading-prompts';

export async function POST(request: NextRequest) {
  const { submissions } = await request.json();
  const prompt = getNewPhasePrompt(submissions);
  // ... API logic
}
```

**Step 3: Add Prompt Function**
```typescript
// lib/prompts/grading-prompts.ts
export function getNewPhasePrompt(submissions: any[]): string {
  return `Your evaluation prompt here...`;
}
```

**Step 4: Update Routing**
- Add route in `app/ranked/new-phase/page.tsx`
- Update phase transitions in `useSession.ts`
- Add phase duration to `lib/constants/scoring.ts`

#### 2. Modifying Scoring Logic

**Edit Constants** (`lib/constants/scoring.ts`):
```typescript
export const SCORING = {
  PHASE1_DURATION: 120,  // Change duration
  DEFAULT_WRITING_SCORE: 75,  // Change default
  // ... other constants
};
```

**Edit Prompts** (`lib/prompts/grading-prompts.ts`):
- Modify scoring criteria in prompt strings
- Adjust evaluation rubrics
- Change feedback requirements

#### 3. Adding New UI Components

**Shared Components** (`components/shared/`):
- Reusable across all modes
- Examples: `PhaseInstructions.tsx`, `WritingTipsModal.tsx`

**Mode-Specific Components** (`components/ranked/`, `components/practice/`):
- Specific to one game mode
- Examples: `WritingSessionContent.tsx`, `PeerFeedbackContent.tsx`

**Base UI Components** (`components/ui/`):
- Low-level UI primitives
- Examples: `Button.tsx`, `Modal.tsx`, `Card.tsx`

#### 4. Adding New API Endpoints

**Pattern to Follow**:
```typescript
// app/api/your-endpoint/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { getAnthropicApiKey, callAnthropicAPI } from '@/lib/utils/api-helpers';
import { parseClaudeJSON } from '@/lib/utils/claude-parser';

export async function POST(request: NextRequest) {
  const requestBody = await request.json();
  const { data } = requestBody;
  
  try {
    const apiKey = getAnthropicApiKey();
    if (!apiKey) {
      return NextResponse.json({ error: 'API key missing' }, { status: 500 });
    }
    
    const prompt = `Your prompt here...`;
    const aiResponse = await callAnthropicAPI(apiKey, prompt, 2000);
    const parsed = parseClaudeJSON(aiResponse.content[0].text);
    
    return NextResponse.json(parsed);
  } catch (error) {
    console.error('Error:', error);
    return NextResponse.json({ error: 'Failed' }, { status: 500 });
  }
}
```

---

## ğŸ“ Learning Science Foundation

### Currently Implemented
âœ… **4-minute timed sessions** (Cognitive Load Theory)  
âœ… **Visual prompts** (Dual coding theory)  
âœ… **Formative AI feedback** (Immediate assessment)  
âœ… **Trait-based rubrics** (Diagnostic evaluation)  
âœ… **Growth mindset messaging** (Effort-based feedback)  
âœ… **Peer feedback** (TAG protocol, ES=0.75)  
âœ… **Three-phase battle system** (Comprehensive assessment)

### Planned for V2
ğŸ”² **Spaced repetition** (10-20% retention interval)  
ğŸ”² **Metacognitive scaffolding** (Self-regulation)  
ğŸ”² **Mastery classification** (Cognitive diagnostic modeling)  
ğŸ”² **Enhanced scaffolding** (Expertise reversal effect)

---

## ğŸ¯ Technology Stack

- **Framework:** Next.js 15 (App Router)
- **Language:** TypeScript
- **Styling:** Tailwind CSS
- **AI:** Anthropic Claude Sonnet 4
- **Database:** Firebase Firestore
- **State:** React hooks + Firestore real-time listeners
- **Future:** PostgreSQL, Prisma, NextAuth, WebSockets

---

## ğŸ“š Documentation

### For Users
- `docs/0_Prototype/V1_SUMMARY.md` - What we built and how to use it
- `docs/5_Setup/SETUP_API.md` - Configure Claude AI feedback

### For Developers
- `DEVELOPER_GUIDE.md` - Comprehensive developer guide (start here!)
- `docs/0_Prototype/FEATURE_CATALOG.md` - Feature comparison with PRD
- `docs/0_Prototype/V2_ROADMAP.md` - Future development plan
- `docs/0_Prototype/PRD.md` - Complete product requirements
- `docs/0_Prototype/PRD_Technical.md` - Technical architecture details
- `docs/2_Refactoring/REFACTORING_OPPORTUNITIES.md` - Additional refactoring ideas
- `docs/README.md` - Complete documentation index

### Design & Research
- `docs/0_Prototype/DESIGN_SCHEMA.md` - Visual design philosophy
- `docs/0_Prototype/PRD_Motivation.md` - Motivation and rewards system
- `docs/0_Prototype/PRD_Assessment.md` - AI evaluation approach
- `docs/0_Prototype/PRD_Risks_Metrics.md` - Risk analysis and metrics

---

## ğŸŒŸ Key Innovations

1. **Counterstrike-Style Matchmaking** - Students form writing "parties" like gaming
2. **AI Player Integration** - AI fills empty slots instantly
3. **Character Evolution** - Visual growth representation (tree growing)
4. **Multi-Mode Strategy** - Practice, Quick, and Ranked for different goals
5. **Instant AI Feedback** - No waiting for teacher grading
6. **Competitive Learning** - Gamification that maintains educational rigor
7. **Batch Ranking System** - Fair comparative evaluation of all submissions
8. **Three-Phase Assessment** - Comprehensive writing skill evaluation

---

## ğŸ® Live Demo Flow

1. Visit landing page: http://localhost:3000
2. Click "Start Writing Now"
3. Choose a game mode (try Practice first!)
4. Follow the setup wizard
5. Write for 4 minutes
6. Get instant AI feedback
7. See your scores and progression

---

## ğŸ”„ Version Control

### Branches
- **`main`** - V1 stable release (current)
- **`v2-features`** - Future development (database, peer feedback, etc.)

### Latest Updates
- âœ… Centralized grading prompts system
- âœ… Refactored utilities and constants
- âœ… Improved error handling and logging
- âœ… Better code organization and maintainability

---

## ğŸ“Š Current Status

**V1 Status:** âœ… **COMPLETE & FUNCTIONAL**

- 45+ features implemented
- 13 pages/routes created
- 3 game modes working
- AI feedback operational
- Three-phase ranked battles
- Batch ranking system
- ~25% of full PRD vision

**Ready for:**
- Demos and presentations
- User testing
- Feedback collection
- Pilot programs (with manual tracking)

**Not ready for:**
- Large-scale deployment (no database)
- Long-term usage (no persistence)
- Classroom management (no teacher tools)

---

## ğŸš€ Next Steps

### Try It Out
```bash
npm run dev
# Visit http://localhost:3000
```

### Configure AI (Optional)
```bash
cp .env.local.example .env.local
# Add your Anthropic API key (see docs/5_Setup/SETUP_API.md)
npm run dev
```

### Start V2 Development
```bash
git checkout v2-features
# Start building database integration!
```

---

## ğŸ‰ Achievements

âœ… Complete user journey from landing to results  
âœ… Three fully functional game modes  
âœ… AI-powered writing assessment  
âœ… Competitive mechanics (rankings, LP, XP)  
âœ… Beautiful, responsive UI  
âœ… Anti-cheating measures  
âœ… Professional polish ready to demo  
âœ… Centralized prompt system for easy editing  
âœ… Refactored codebase for maintainability  

**V1 is a success!** Ready to show stakeholders and gather feedback for V2 priorities.

See `FEATURE_CATALOG.md` for detailed feature inventory and `V2_ROADMAP.md` for future development plans.

---

*Built with Learning Science principles and competitive gaming mechanics to transform K-12 writing instruction.*
